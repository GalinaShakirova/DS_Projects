{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заказчик**: Интернет-магазин «Викишоп».\n",
    "\n",
    "Интернет-магазин запускает новый сервис, где пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "\n",
    "**Входные данные**: набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Задача:** обучить модель классифицировать комментарии на позитивные и негативные. Значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "Параметры:\n",
    "- text - текст комментария,\n",
    "- toxic - целевой признак.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Обзор-данных\" data-toc-modified-id=\"Обзор-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Обзор данных</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Лемматизация-или-стемминг?\" data-toc-modified-id=\"Лемматизация-или-стемминг?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Лемматизация или стемминг?</a></span></li><li><span><a href=\"#Разделение-на-обучающую,-валидационную-и--тестовую--выборки\" data-toc-modified-id=\"Разделение-на-обучающую,-валидационную-и--тестовую--выборки-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Разделение на обучающую, валидационную и  тестовую  выборки</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>TF-IDF</a></span></li></ul></li><li><span><a href=\"#Создание-моделей\" data-toc-modified-id=\"Создание-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Создание моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#DecisionTreeClassifier\" data-toc-modified-id=\"DecisionTreeClassifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>DecisionTreeClassifier</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#Проверка-модели-на-адекватность\" data-toc-modified-id=\"Проверка-модели-на-адекватность-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Проверка модели на адекватность</a></span></li></ul></li><li><span><a href=\"#BERT-и-LogisticRegression\" data-toc-modified-id=\"BERT-и-LogisticRegression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>BERT и LogisticRegression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Предобработка-с-использованием-модели-DistilBERT\" data-toc-modified-id=\"Предобработка-с-использованием-модели-DistilBERT-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Предобработка с использованием модели DistilBERT</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>LogisticRegression</a></span></li></ul></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала импортируем необходимые в работе библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-3c6f4a55ba75>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  from tqdm._tqdm_notebook import tqdm_notebook\n",
      "/Users/galina/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "[nltk_data] Downloading package punkt to /Users/galina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/galina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/galina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/galina/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#библиотеки для преобразования текста\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\n",
    "#библиотеки для моделирования\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit, cross_val_score, KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#BERT\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные в таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим общую информацию об исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 80.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())\n",
    "display(df.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица с исходными данными **df** содержит 159571 строк и 2 столбца, пропуски отсутствуют.\n",
    "\n",
    "Посмотрим на распределение целевого признака.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что классы не сбалансированные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим данные для моделирования, для этого:\n",
    "- лемматизируем комментарии;\n",
    "- разделим выборки на обучающую (60%), валидационную(20%) и тестовую (20%);\n",
    "- выделим корпус на обучающих данных и вычислим TF-IDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация или стемминг?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы определиться с методом предобработки текста (лемматизация с использованием \"POS tag\" (к какой части речи относится слово) или сетмминг), который будем использовать для предобработки комментариев, сравним их результаты. \n",
    "\n",
    "Для начала напишем функции для очистки текста от лишних символов, используя регулярные выражения, а также функцию, которая будет возвращать \"POS tag\" для слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    '''Очищает текст от лишних символов и приводит к нижнему регистру'''\n",
    "    #text_re = re.sub(r'[^\\w ]',' ',text) A-Fa-f\n",
    "    text_re = re.sub(r'[\\W \\d]',' ',text)\n",
    "    text_split = text_re.lower().split()\n",
    "    text_list = ' '.join(text_split)\n",
    "    \n",
    "    return text_list\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Определяет POS tag для слова, основываясь на словаре tag_dict\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу инициализируем необходимые функции для лемматизации, стемминга и список стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним лемматизацию и стемминг на одном комментарии. Для начала очистим текст от лишних символов, токенизируем по словам и уберем стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст без лишних символов: \n",
      " hey man i m really not trying to edit war it s just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page he seems to care more about the formatting than the actual info \n",
      "-------------------------------\n",
      "Токенизированный текст: \n",
      " ['hey', 'man', 'i', 'm', 'really', 'not', 'trying', 'to', 'edit', 'war', 'it', 's', 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info'] \n",
      "-------------------------------\n",
      "Токенизированный текст без стоп-слов: \n",
      " ['hey', 'man', 'really', 'trying', 'edit', 'war', 'guy', 'constantly', 'removing', 'relevant', 'information', 'talking', 'edits', 'instead', 'talk', 'page', 'seems', 'care', 'formatting', 'actual', 'info'] \n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "#очищает текст от лишних символов\n",
    "text_clear = clear_text(df.loc[2,'text'])\n",
    "print('Текст без лишних символов:',\n",
    "      '\\n',\n",
    "      text_clear,\n",
    "     '\\n-------------------------------')\n",
    "\n",
    "#токенизирует по словам\n",
    "text_token = word_tokenize(text_clear)\n",
    "print('Токенизированный текст:',\n",
    "      '\\n',\n",
    "      text_token,\n",
    "     '\\n-------------------------------')\n",
    "\n",
    "#убирает стоп-слова\n",
    "text_token_without_stop_words = [\n",
    "    word for word in text_token if word not in stop_words\n",
    "]\n",
    "print('Токенизированный текст без стоп-слов:',\n",
    "      '\\n',\n",
    "      text_token_without_stop_words,\n",
    "     '\\n-------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сравним результат, выдаваемый лемматизацией и стеммингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Стемминг: \n",
      " ['hey', 'man', 'realli', 'tri', 'edit', 'war', 'guy', 'constant', 'remov', 'relev', 'inform', 'talk', 'edit', 'instead', 'talk', 'page', 'seem', 'care', 'format', 'actual', 'info'] \n",
      "-------------------------------\n",
      "Лемматизация с учетом POS tag: \n",
      " ['hey', 'man', 'really', 'try', 'edit', 'war', 'guy', 'constantly', 'remove', 'relevant', 'information', 'talk', 'edits', 'instead', 'talk', 'page', 'seem', 'care', 'format', 'actual', 'info']\n"
     ]
    }
   ],
   "source": [
    "#стемминг\n",
    "stem_text = [stemmer.stem(word) for word in text_token_without_stop_words]\n",
    "print('Стемминг:',\n",
    "      '\\n',\n",
    "      stem_text,\n",
    "     '\\n-------------------------------')\n",
    "\n",
    "#лемматизация с учетом POS tag\n",
    "lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text_token_without_stop_words]\n",
    "print('Лемматизация с учетом POS tag:',\n",
    "      '\\n',\n",
    "      lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что для слова \"trying\" стемминг выдал - \"tri\", а лемматизация с учетом POS tag - \"try\". Аналогичную ситуацию наблюдаем и по другим словам, например: \"removing\", \"relevant\" и др.\n",
    "\n",
    "Результаты, получаемые при лемматизации, кажутся более верным решением. Будем использовать ее для предобработки текста. Напишем функцию для лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    '''Возвращает лемматизированный список слов, очищенный от лишних символов и стоп-слов'''\n",
    "    #очищает текст от лишних символов\n",
    "    text_clear = clear_text(text)\n",
    "    #токенизирует по словам\n",
    "    text_token = word_tokenize(text_clear)\n",
    "    #убирает стоп-слова\n",
    "    text_token_without_stop_words = [\n",
    "        word for word in text_token if word not in stop_words\n",
    "    ]\n",
    "    #лемматизирует, учитывая POS tag\n",
    "    lemma = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in text_token_without_stop_words]\n",
    "    \n",
    "    return \" \".join(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим ее работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation edits make username hardcore metallica fan revert vandalism closure gas vote new york doll fac please remove template talk page since retire'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_text(df.loc[0,'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит корректно.  С ее помощью создадим параметр **'lem_text'**. используя метод `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3faa0c5930864f79919d380b3255438e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['lemm_text'] = df['text'].progress_apply(lambda x: lemm_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем 5 первых строк таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits make username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation edits make username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really try edit war guy constantly rem...  \n",
       "3  make real suggestion improvement wonder sectio...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, комментарии очистили и лемматизировали. Разделим данные на выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные выводы:** приняли решение использовать при предобработки комментариев лемматизацию. Ее результат выглядит более корректным для целей проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на обучающую, валидационную и  тестовую  выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборки на обучающую (60%), валидационную(20%) и тестовую (20%). Чтобы выборки были репрезентативные, используем стратификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выделяет тестовую выборку\n",
    "df_train, test = train_test_split(df, test_size=0.2, random_state=13, stratify=df['toxic'])\n",
    "\n",
    "#выделяет обучающую и валидационную выборки\n",
    "train, valid = train_test_split(df_train, test_size=0.25, random_state=13, stratify=df_train['toxic'])\n",
    "\n",
    "#выделяет признаки и целевой признак\n",
    "#features_train = train['lemm_text']\n",
    "target_train = train['toxic']\n",
    "\n",
    "#features_valid = valid['lemm_text']\n",
    "target_valid = valid['toxic']\n",
    "\n",
    "#features_test = test['lemm_text']\n",
    "target_test = test['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, как разделились данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка размера полученных выборок: \n",
      "\n",
      "Исходный размер таблицы: (159571, 3)\n",
      "Размер таблицы train : (95742, 3)\n",
      "Размер таблицы target_train : (95742,)\n",
      "Размер таблицы valid : (31914, 3)\n",
      "Размер таблицы target_valid : (31914,)\n",
      "Размер таблицы test : (31915, 3)\n",
      "Размер таблицы target_test : (31915,)\n",
      " \n",
      "Доля обучающей выборки от исходной таблицы: 60%\n",
      "Доля валидационной выборки от исходной таблицы: 20%\n",
      "Доля тестовой выборки от исходной таблицы: 20% \n",
      "\n",
      "Проверка долей каждой группы в полученных выборках:\n",
      "\n",
      " train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic\n",
       "0  0.89832\n",
       "1  0.10168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " valid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.89832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic\n",
       "0  0.89832\n",
       "1  0.10168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic\n",
       "0  0.898324\n",
       "1  0.101676"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Проверка размера полученных выборок:',\n",
    "     '\\n')\n",
    "print('Исходный размер таблицы:', df.shape)\n",
    "    \n",
    "for data in [train, target_train, valid, target_valid, test, target_test]:\n",
    "    name =[x for x in globals() if globals()[x] is data][0]\n",
    "    print('Размер таблицы',name,':', data.shape)\n",
    "    \n",
    "print('',\n",
    "    '\\nДоля обучающей выборки от исходной таблицы: {:.0%}'.format(train.shape[0]/len(df)))\n",
    "print('Доля валидационной выборки от исходной таблицы: {:.0%}'.format(valid.shape[0]/len(df)))\n",
    "print('Доля тестовой выборки от исходной таблицы: {:.0%}'.format(test.shape[0]/len(df)),\n",
    "     '\\n')\n",
    "\n",
    "print('Проверка долей каждой группы в полученных выборках:')\n",
    "for data in [train, valid, test]:\n",
    "    name =[x for x in globals() if globals()[x] is data][0]\n",
    "    print('\\n',name)\n",
    "    display(data['toxic'].value_counts(normalize=True).to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные разделены корректно, соотношение групп по целевому признаку соблюдены. Теперь можно перейти к расчету TF-IDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные выводы:** выделили три выборки: обучающая (60%)б валидационная (20%) и тестовая (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем корпус из лемматизированных комментариев обучающей выборки и рассчитаем TF-IDF для всех трех выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (95742, 116017)\n",
      "Размер матрицы: (31914, 116017)\n",
      "Размер матрицы: (31915, 116017)\n"
     ]
    }
   ],
   "source": [
    "#формирует корпус на основе обучающей выборки\n",
    "corpus = train['lemm_text'].values.astype('U')\n",
    "\n",
    "#создает счетчик и обучается\n",
    "count_tf_idf = TfidfVectorizer() \n",
    "features_train = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "#формирует признаки для валидационной и тестовой выборок\n",
    "features_valid = count_tf_idf.transform(valid['lemm_text'].values.astype('U')) \n",
    "features_test = count_tf_idf.transform(test['lemm_text'].values.astype('U')) \n",
    "\n",
    "print(\"Размер матрицы:\", features_train.shape)\n",
    "print(\"Размер матрицы:\", features_valid.shape)\n",
    "print(\"Размер матрицы:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к созданию моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные выводы:** сформировали признаки для всех трех выборок, рассчитав TF-IDF для каждого комментария."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и обучим четыре модели: \n",
    "- LogisticRegression\n",
    "- DecisionTreeClassifier\n",
    "- RandomForestClassifier\n",
    "- CatBoostClassifier\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой построим модель логистической регрессии с использованием кросс-валидации. Проблему с дисбалансом классов решим их взвешиванием, указав в модели параметр `class_weight` равный **'balanced'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegressionCV(cv=5, random_state=13, solver='liblinear', class_weight='balanced')\n",
    "\n",
    "#обучение модели\n",
    "start_log_train = time.time()\n",
    "model_logistic.fit(features_train, target_train)\n",
    "end_log_train = time.time()\n",
    "\n",
    "time_log_train = str(timedelta(seconds=(end_log_train-start_log_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для получения предсказаний и метрики, а также времени предсказания. Применим ее на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.764 \n",
      "Время предсказания: 0:00:00.002344\n"
     ]
    }
   ],
   "source": [
    "def pred_with_time(model, features, target):\n",
    "    '''Возвращает F1-меру и время предсказания'''\n",
    "    start = time.time()\n",
    "    prediction = model.predict(features)\n",
    "    end = time.time()\n",
    "    \n",
    "    time_pred = str(timedelta(seconds=(end-start)))\n",
    "\n",
    "    f1 = f1_score(target, prediction)\n",
    "    print('F1-мера: {:.3f}'.format(f1),\n",
    "         '\\nВремя предсказания:',time_pred)\n",
    "    \n",
    "    return f1, time_pred\n",
    "\n",
    "f1_valid_logistic, time_log_pred_valid = pred_with_time(model_logistic, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке получили значение F1-меры равное 0.764. Теперь получим метрику для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.756 \n",
      "Время предсказания: 0:00:00.002983\n"
     ]
    }
   ],
   "source": [
    "f1_test_logistic, time_log_pred_test = pred_with_time(model_logistic, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке получили F1-меры равное 0.756. Метрика на валидационной и тестовой выборках не сильно отличается. Сформируем итоговую таблицу по всем моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 valid</th>\n",
       "      <th>F1 test</th>\n",
       "      <th>Time grid/train</th>\n",
       "      <th>Time prediction valid</th>\n",
       "      <th>Time prediction test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.756459</td>\n",
       "      <td>0:01:08.553059</td>\n",
       "      <td>0:00:00.002344</td>\n",
       "      <td>0:00:00.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  F1 valid   F1 test Time grid/train  \\\n",
       "0  LogisticRegression  0.763848  0.756459  0:01:08.553059   \n",
       "\n",
       "  Time prediction valid Time prediction test  \n",
       "0        0:00:00.002344       0:00:00.002983  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\"Model\": [\"LogisticRegression\"],\n",
    "                       \"F1 valid\": [f1_valid_logistic], \n",
    "                       \"F1 test\": [f1_test_logistic],\n",
    "                       \"Time grid/train\": [time_log_train],\n",
    "                       \"Time prediction valid\": [time_log_pred_valid],\n",
    "                       \"Time prediction test\": [time_log_pred_test],\n",
    "                       \n",
    "                      })\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая обученная модель выдает необходимую нам метрику, при этом обучение занимает чуть больше 1 минуты, а предсказывает достаточно быстро.\n",
    "\n",
    "Перейдем к следующей модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель решающее дерево и с помощью функции `GridSearchCV` подберем параметры. \n",
    "\n",
    "Создадим через функцию KFold условия для выборок в кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = KFold(n_splits=5, random_state=13, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель, также указав параметр `class_weight` равный **'balanced'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 ms, sys: 5.88 ms, total: 17.6 ms\n",
      "Wall time: 3.21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator_tree = DecisionTreeClassifier(random_state=13,\n",
    "                                    class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список перебираемых параметров и передадим их в `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.608\n",
      "Лучшие параметры {'max_depth': 13, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Время train: 0:23:46.792794\n"
     ]
    }
   ],
   "source": [
    "#список перебираемых параметров\n",
    "param_tree = {'max_depth': np.arange(13, 14, 1),\n",
    "              'min_samples_split': np.arange(2, 3, 1),\n",
    "              'min_samples_leaf': np.arange(2, 3, 1)}\n",
    "\n",
    "\n",
    "start_tree_grid_train = time.time()\n",
    "#подбирает гиперпараметры\n",
    "model_tree = GridSearchCV(estimator_tree, param_tree, scoring='f1', cv=shuffle)\n",
    "\n",
    "#обучает модель\n",
    "model_tree.fit(features_train, target_train)\n",
    "end_tree_grid_train= time.time()\n",
    "\n",
    "#время обучения\n",
    "#time_tree_grid_train=str(timedelta(seconds=(end_tree_grid_train-start_tree_grid_train)))\n",
    "time_tree_grid_train='0:23:46.792794'\n",
    "\n",
    "print('F1-мера: {:.3f}'.format(model_tree.best_score_))\n",
    "print('Лучшие параметры',model_tree.best_params_)\n",
    "print('Время train:', time_tree_grid_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели DecisionTreeClassifier получили лучшее значение F1-меры равное 0.609 при следующих гиперпараметрах:\n",
    "- `max_depth`: 13\n",
    "- `min_samples_leaf`: 2, \n",
    "- `min_samples_split`: 2.\n",
    "\n",
    "\n",
    "Получим предсказание и метрику для валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.615 \n",
      "Время предсказания: 0:00:00.013638\n"
     ]
    }
   ],
   "source": [
    "f1_valid_tree, time_tree_pred_valid = pred_with_time(model_tree, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке получили значение F1-меры равное 0.615. Теперь получим метрику для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.591 \n",
      "Время предсказания: 0:00:00.012319\n"
     ]
    }
   ],
   "source": [
    "f1_test_tree, time_tree_pred_test = pred_with_time(model_tree, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке получили F1-меру равную 0.591.  Сформируем итоговую таблицу по всем моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 valid</th>\n",
       "      <th>F1 test</th>\n",
       "      <th>Time grid/train</th>\n",
       "      <th>Time prediction valid</th>\n",
       "      <th>Time prediction test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.614799</td>\n",
       "      <td>0.591169</td>\n",
       "      <td>0:23:46.792794</td>\n",
       "      <td>0:00:00.013638</td>\n",
       "      <td>0:00:00.012319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.756459</td>\n",
       "      <td>0:01:08.553059</td>\n",
       "      <td>0:00:00.002344</td>\n",
       "      <td>0:00:00.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1 valid   F1 test Time grid/train  \\\n",
       "1  DecisionTreeClassifier  0.614799  0.591169  0:23:46.792794   \n",
       "0      LogisticRegression  0.763848  0.756459  0:01:08.553059   \n",
       "\n",
       "  Time prediction valid Time prediction test  \n",
       "1        0:00:00.013638       0:00:00.012319  \n",
       "0        0:00:00.002344       0:00:00.002983  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append({\"Model\": \"DecisionTreeClassifier\",\n",
    "                       \"F1 valid\": f1_valid_tree, \n",
    "                       \"F1 test\": f1_test_tree,\n",
    "                       \"Time grid/train\": time_tree_grid_train,\n",
    "                       \"Time prediction valid\": time_tree_pred_valid,\n",
    "                       \"Time prediction test\": time_tree_pred_test}, ignore_index=True)\n",
    "\n",
    "result.sort_values(by='F1 test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат модели дерева решений хуже, чем у логистической регрессии, при этом время обучения и предсказания у значительно превышает модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель RandomForestRegressor и подберем гиперпараметры с помощью функции GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(random_state=13, class_weight='balanced', n_estimators=400) \n",
    "\n",
    "#формирует гиперпараметры и их значения для перебора в функции GridSearchCV\n",
    "param_forest = { \n",
    "    'min_samples_split': np.arange(4, 5, 1)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем гиперпараметры и обучим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.665\n",
      "Лучшие параметры {'min_samples_split': 4}\n"
     ]
    }
   ],
   "source": [
    "start_forest_grid_train = time.time()\n",
    "#подбирает гиперпараметры\n",
    "model_forest = GridSearchCV(model_forest, param_forest, scoring='f1', cv=shuffle)\n",
    "\n",
    "#обучает модель\n",
    "model_forest.fit(features_train, target_train)\n",
    "end_forest_grid_train = time.time()\n",
    "\n",
    "#время обучения\n",
    "#time_forest_grid_train=str(timedelta(seconds=(end_forest_grid_train-start_forest_grid_train)))\n",
    "time_forest_grid_train='0:33:46.963650'\n",
    "\n",
    "print('F1-мера: {:.3f}'.format(model_forest.best_score_))\n",
    "print('Лучшие параметры',model_forest.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели RandomForestClassifier получили лучшее значение F1-меры при гиперпараметрах, равных:\n",
    "- `min_samples_split`: 4, \n",
    "- `n_estimators`: 400\n",
    "\n",
    "\n",
    "Получим предсказание и метрику для валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.678 \n",
      "Время предсказания: 0:00:09.981652\n"
     ]
    }
   ],
   "source": [
    "f1_forest_valid, time_forest_pred_valid = pred_with_time(model_forest,features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке значение F1-меры равно 0.678. Посчитаем для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.657 \n",
      "Время предсказания: 0:00:09.791373\n"
     ]
    }
   ],
   "source": [
    "f1_forest_test, time_forest_pred_test = pred_with_time(model_forest,features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке значение F1-меры равно 0.657. Добавим в сводную таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 valid</th>\n",
       "      <th>F1 test</th>\n",
       "      <th>Time grid/train</th>\n",
       "      <th>Time prediction valid</th>\n",
       "      <th>Time prediction test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.614799</td>\n",
       "      <td>0.591169</td>\n",
       "      <td>0:23:46.792794</td>\n",
       "      <td>0:00:00.013638</td>\n",
       "      <td>0:00:00.012319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.678315</td>\n",
       "      <td>0.656558</td>\n",
       "      <td>0:33:46.963650</td>\n",
       "      <td>0:00:09.981652</td>\n",
       "      <td>0:00:09.791373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.756459</td>\n",
       "      <td>0:01:08.553059</td>\n",
       "      <td>0:00:00.002344</td>\n",
       "      <td>0:00:00.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1 valid   F1 test Time grid/train  \\\n",
       "1  DecisionTreeClassifier  0.614799  0.591169  0:23:46.792794   \n",
       "2  RandomForestClassifier  0.678315  0.656558  0:33:46.963650   \n",
       "0      LogisticRegression  0.763848  0.756459  0:01:08.553059   \n",
       "\n",
       "  Time prediction valid Time prediction test  \n",
       "1        0:00:00.013638       0:00:00.012319  \n",
       "2        0:00:09.981652       0:00:09.791373  \n",
       "0        0:00:00.002344       0:00:00.002983  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append({\"Model\": \"RandomForestClassifier\", \n",
    "                        \"F1 valid\": f1_forest_valid, \n",
    "                        \"F1 test\": f1_forest_test,\n",
    "                        \"Time grid/train\": time_forest_grid_train,\n",
    "                        \"Time prediction valid\": time_forest_pred_valid,\n",
    "                        \"Time prediction test\": time_forest_pred_test}, ignore_index=True)\n",
    "\n",
    "result.sort_values(by='F1 test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса предсказала лучше, чем модель дерева решений, но все же уступает модели логистической регрессии. Время обучения и подбора гиперпараметров самое долгое у случайного леса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель CatBoostClassifier и подберем гиперпараметры с помощью функции GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим веса для несбалансированных классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.835"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = round((len(target_train[target_train == 0]) / \n",
    "                          len(target_train[target_train == 1])), 3)\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.074541\n",
      "0:\tlearn: 0.4638620\ttest: 0.4638620\tbest: 0.4638620 (0)\ttotal: 331ms\tremaining: 5m 30s\n",
      "100:\tlearn: 0.8400586\ttest: 0.8400586\tbest: 0.8400586 (100)\ttotal: 22.8s\tremaining: 3m 22s\n",
      "200:\tlearn: 0.8875162\ttest: 0.8875162\tbest: 0.8879512 (199)\ttotal: 44.9s\tremaining: 2m 58s\n",
      "300:\tlearn: 0.9200461\ttest: 0.9200461\tbest: 0.9200461 (300)\ttotal: 1m 7s\tremaining: 2m 35s\n",
      "400:\tlearn: 0.9373096\ttest: 0.9373096\tbest: 0.9373096 (400)\ttotal: 1m 29s\tremaining: 2m 13s\n",
      "500:\tlearn: 0.9510829\ttest: 0.9510829\tbest: 0.9510829 (500)\ttotal: 1m 51s\tremaining: 1m 51s\n",
      "600:\tlearn: 0.9700110\ttest: 0.9700110\tbest: 0.9701704 (599)\ttotal: 2m 13s\tremaining: 1m 28s\n",
      "700:\tlearn: 0.9860316\ttest: 0.9860316\tbest: 0.9860316 (698)\ttotal: 2m 35s\tremaining: 1m 6s\n",
      "800:\tlearn: 0.9883612\ttest: 0.9883612\tbest: 0.9883612 (799)\ttotal: 2m 58s\tremaining: 44.3s\n",
      "900:\tlearn: 0.9894898\ttest: 0.9894898\tbest: 0.9895411 (893)\ttotal: 3m 20s\tremaining: 22s\n",
      "999:\tlearn: 0.9906188\ttest: 0.9906188\tbest: 0.9906188 (994)\ttotal: 3m 42s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9906188296\n",
      "bestIteration = 994\n",
      "\n",
      "Shrink model to first 995 iterations.\n",
      "CPU times: user 12min 17s, sys: 6min 8s, total: 18min 25s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_cat = CatBoostClassifier(random_state = 13, verbose=100, eval_metric='F1',\n",
    "                              scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "\n",
    "start_cat_train = time.time()\n",
    "model_cat.fit(features_valid, target_valid,eval_set=(features_valid, target_valid))\n",
    "end_cat_train = time.time()\n",
    "\n",
    "#время обучения\n",
    "time_cat_train=str(timedelta(seconds=(end_cat_train-start_cat_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.924 \n",
      "Время предсказания: 0:00:00.304970\n"
     ]
    }
   ],
   "source": [
    "f1_cat_valid, time_cat_pred_valid = pred_with_time(model_cat, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке значение F1-меры равно 0.924. Посчитаем для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.747 \n",
      "Время предсказания: 0:00:00.307244\n"
     ]
    }
   ],
   "source": [
    "f1_cat_test, time_cat_pred_test = pred_with_time(model_cat, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке значение F1-меры равно 0.747. Добавим в итоговую таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 valid</th>\n",
       "      <th>F1 test</th>\n",
       "      <th>Time grid/train</th>\n",
       "      <th>Time prediction valid</th>\n",
       "      <th>Time prediction test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.614799</td>\n",
       "      <td>0.591169</td>\n",
       "      <td>0:23:46.792794</td>\n",
       "      <td>0:00:00.013638</td>\n",
       "      <td>0:00:00.012319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.678315</td>\n",
       "      <td>0.656558</td>\n",
       "      <td>0:33:46.963650</td>\n",
       "      <td>0:00:09.981652</td>\n",
       "      <td>0:00:09.791373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.923822</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0:03:45.202968</td>\n",
       "      <td>0:00:00.304970</td>\n",
       "      <td>0:00:00.307244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.756459</td>\n",
       "      <td>0:01:08.553059</td>\n",
       "      <td>0:00:00.002344</td>\n",
       "      <td>0:00:00.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1 valid   F1 test Time grid/train  \\\n",
       "1  DecisionTreeClassifier  0.614799  0.591169  0:23:46.792794   \n",
       "2  RandomForestClassifier  0.678315  0.656558  0:33:46.963650   \n",
       "3      CatBoostClassifier  0.923822  0.746722  0:03:45.202968   \n",
       "0      LogisticRegression  0.763848  0.756459  0:01:08.553059   \n",
       "\n",
       "  Time prediction valid Time prediction test  \n",
       "1        0:00:00.013638       0:00:00.012319  \n",
       "2        0:00:09.981652       0:00:09.791373  \n",
       "3        0:00:00.304970       0:00:00.307244  \n",
       "0        0:00:00.002344       0:00:00.002983  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append({\"Model\": \"CatBoostClassifier\", \n",
    "                       \"F1 valid\": f1_cat_valid, \n",
    "                       \"F1 test\": f1_cat_test,\n",
    "                       \"Time grid/train\": time_cat_train,\n",
    "                       \"Time prediction valid\": time_cat_pred_valid,\n",
    "                       \"Time prediction test\": time_cat_pred_test}, ignore_index=True)\n",
    "\n",
    "result.sort_values(by='F1 test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение F1-меры на тестовой выборке для моделей LogisticRegression и CatBoostClassifier близки, но модель CatBoostClassifier требует гораздо больше времени на обучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модели на адекватность с помощью модели **DummyClassifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(random_state=13, strategy=\"stratified\")\n",
    "\n",
    "#обучает модель\n",
    "start_dummy_train = time.time()\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "end_dummy_train = time.time()\n",
    "\n",
    "#время обучения\n",
    "time_dummy_train=str(timedelta(seconds=(end_dummy_train-start_dummy_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на результат модели на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.101 \n",
      "Время предсказания: 0:00:00.001671\n"
     ]
    }
   ],
   "source": [
    "f1_dummy_valid, time_dummy_pred_valid = pred_with_time(dummy_clf, features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидационной выборке значение F1-меры равно 0.101. Посчитаем для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.102 \n",
      "Время предсказания: 0:00:00.001417\n"
     ]
    }
   ],
   "source": [
    "f1_dummy_test, time_dummy_pred_test = pred_with_time(dummy_clf, features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке значение F1-меры равно 0.102. Добавим результаты в сводную таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 valid</th>\n",
       "      <th>F1 test</th>\n",
       "      <th>Time grid/train</th>\n",
       "      <th>Time prediction valid</th>\n",
       "      <th>Time prediction test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.100679</td>\n",
       "      <td>0.101915</td>\n",
       "      <td>0:00:00.002179</td>\n",
       "      <td>0:00:00.001671</td>\n",
       "      <td>0:00:00.001417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.614799</td>\n",
       "      <td>0.591169</td>\n",
       "      <td>0:23:46.792794</td>\n",
       "      <td>0:00:00.013638</td>\n",
       "      <td>0:00:00.012319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.678315</td>\n",
       "      <td>0.656558</td>\n",
       "      <td>0:33:46.963650</td>\n",
       "      <td>0:00:09.981652</td>\n",
       "      <td>0:00:09.791373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.923822</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0:03:45.202968</td>\n",
       "      <td>0:00:00.304970</td>\n",
       "      <td>0:00:00.307244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.763848</td>\n",
       "      <td>0.756459</td>\n",
       "      <td>0:01:08.553059</td>\n",
       "      <td>0:00:00.002344</td>\n",
       "      <td>0:00:00.002983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  F1 valid   F1 test Time grid/train  \\\n",
       "4         DummyClassifier  0.100679  0.101915  0:00:00.002179   \n",
       "1  DecisionTreeClassifier  0.614799  0.591169  0:23:46.792794   \n",
       "2  RandomForestClassifier  0.678315  0.656558  0:33:46.963650   \n",
       "3      CatBoostClassifier  0.923822  0.746722  0:03:45.202968   \n",
       "0      LogisticRegression  0.763848  0.756459  0:01:08.553059   \n",
       "\n",
       "  Time prediction valid Time prediction test  \n",
       "4        0:00:00.001671       0:00:00.001417  \n",
       "1        0:00:00.013638       0:00:00.012319  \n",
       "2        0:00:09.981652       0:00:09.791373  \n",
       "3        0:00:00.304970       0:00:00.307244  \n",
       "0        0:00:00.002344       0:00:00.002983  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append({\"Model\": \"DummyClassifier\", \n",
    "                        \"F1 valid\": f1_dummy_valid, \n",
    "                        \"F1 test\": f1_dummy_test,\n",
    "                        \"Time grid/train\": time_dummy_train,\n",
    "                        \"Time prediction valid\": time_dummy_pred_valid,\n",
    "                        \"Time prediction test\": time_dummy_pred_test}, ignore_index=True)\n",
    "\n",
    "result.sort_values(by='F1 test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайная модель показала самую низкую метрику из всех, отличие существенное. У рассмотренных моделей гораздо выше качество предсказания. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные итоги:**\n",
    "\n",
    "1. Необходимую метрику показала только модель LogisticRegression.\n",
    "\n",
    "2. Результаты модели CatBoostClassifier близки к результатам модели LogisticRegression, но при этом CatBoostClassifier требует гораздо больше времени на обучение даже без подбора параметров.\n",
    "\n",
    "2. Третий результат показала модель RandomForestClassifier, но у нее самое длительное время обучения и подбора гиперпараметров.\n",
    "\n",
    "3. Последний результат показала модель DecisionTreeClassifier, время обучения на уровне модели CatBoostClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT и LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка с использованием модели DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT представляет собой уменьшенную версию BERT. Она быстрее и легче, но не уступает по результативности. Будем использовать ее.\n",
    "\n",
    "Загрузим предобученную модель DistilBERT и токенайзер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.BertModel, ppb.BertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "#BERT\n",
    "#model_class, tokenizer_class, pretrained_weights = (\n",
    "#    ppb.DistilBertModel, ppb.DistilBertTokenizer, 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим предобученные токенайзер и модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertModel: ['distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'vocab_transform.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.9.attention.output.LayerNorm.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.11.attention.output.dense.weight', 'pooler.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model_bert = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним токенезацию комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599d37b9205e419595b8607d82933b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=159571.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['token'] = df['text'].progress_apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что у нас получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n",
       "1    [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n",
       "2    [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n",
       "3    [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n",
       "4    [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n",
       "Name: token, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какя максимальная длина комментариев с токенами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(i) for i in df['token']])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель DistilBERT принимает максимальное количество токенов в тексте по умолчанию равное 512. В нашем случае явное превышение этого числа. Посмотрим на распределение длин комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_tok = pd.DataFrame([len(i) for i in df['token']], columns=['len_tok'])\n",
    "len_tok.plot.hist(bins=100, range=(0,512), figsize=(9,6), xlabel='Длина комментария')\n",
    "\n",
    "#задает форматирование\n",
    "plt.xlabel('Длина комментария')\n",
    "plt.title('Распределение длины комментариев с токенами')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из распределения видим, что основная длина комментариев находится в диапазоне до 300 токенов. Уберем аномальные длины, в качестве порогового значения возьмем 75% квантиль."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% квантиль длины комментариев: len_tok    104.0\n",
      "Name: 0.75, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('75% квантиль длины комментариев:',len_tok.quantile(.75))\n",
    "\n",
    "#формирует список индексов строк, в которых длина комментария не превышает пороговое значение\n",
    "df['token_len'] = df['token'].apply(len)\n",
    "indexes = list(df[df['token_len'] <= len_tok.quantile(.75)[0]].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы хватило оперативной памяти, сформируем небольшую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изначальный размер таблицы (159571, 5)\n",
      "Размер таблицы с длиной комментария до 104: (119975, 5)\n",
      "Размер выборки: (20000, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Изначальный размер таблицы', df.shape)\n",
    "\n",
    "df_bert = df.loc[indexes].copy()\n",
    "print('Размер таблицы с длиной комментария до 104:',df_bert.shape)\n",
    "\n",
    "df_bert_sample = df_bert.sample(20000,random_state=13).reset_index(drop=True)\n",
    "\n",
    "print('Размер выборки:',df_bert_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим максимальную длину комментария из выборки для применения метода `padding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max([len(i) for i in df_bert_sample['token']])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод `padding`, чтобы выравнить длину векторов, заполнив недостающие значения 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6855c4f78c4f86b11ff5e12b991ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 104)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tqdm(df_bert_sample['token'].values)])\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим маску, где укажем, что нули не несут важной информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим маску для важных токенов\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 104)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем тексты в эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acf069ebbfd40169502f0966776667d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model_bert(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицу признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 768)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.concatenate(embeddings)\n",
    "features = pd.DataFrame(features, index=df_bert_sample.index)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим на обучающую и тестовую выборки. Так как мы изначально взяли небольшую выборку для получения матрицы признаков, сделаем тестовую выборку размером 20%, чтобы модель могла обучиться на большем количестве данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер features_train_bert (16000, 768)\n",
      "Размер features_test_bert (4000, 768)\n",
      "Размер target_train_bert (16000,)\n",
      "Размер target_train_bert (4000,)\n"
     ]
    }
   ],
   "source": [
    "#выделяет обучающую и тестовую выборки из матрицы признаков\n",
    "features_train_bert, features_test_bert = train_test_split(features, test_size=0.2, random_state=13)\n",
    "print('Размер features_train_bert',features_train_bert.shape)\n",
    "print('Размер features_test_bert',features_test_bert.shape)\n",
    "\n",
    "#формирует целевые признаки для выборок\n",
    "target_train_bert = df_bert_sample.loc[(df_bert_sample.index.isin(features_train_bert.index)),'toxic']\n",
    "target_test_bert = df_bert_sample.loc[(df_bert_sample.index.isin(features_test_bert.index)),'toxic']\n",
    "print('Размер target_train_bert',target_train_bert.shape)\n",
    "print('Размер target_train_bert',target_test_bert.shape)\n",
    "\n",
    "\n",
    "features_train_bert = features_train_bert.sort_index()\n",
    "target_train_bert = target_train_bert.sort_index()\n",
    "\n",
    "features_test_bert = features_test_bert.sort_index()\n",
    "target_test_bert  = target_test_bert.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточные итоги:**\n",
    "- Токенизировали комментарии. \n",
    "- Устранили аномально длинные комметарии, в качестве порога взяв 75% квантиль. \n",
    "- Применили метод `padding`.\n",
    "- Сформировали обучающую (80%) и тестовую(20%) выборки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель логистической регрессии с теми же параметрами, которые уже использовали ранее без применения модели BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время обучения: 0:06:42.261472\n"
     ]
    }
   ],
   "source": [
    "model_logistic_bert = model_logistic = LogisticRegressionCV(cv=5, \n",
    "                                                            random_state=13, \n",
    "                                                            solver='liblinear',\n",
    "                                                            class_weight='balanced')\n",
    "\n",
    "start_log_bert_train = time.time()\n",
    "model_logistic_bert.fit(features_train_bert, target_train_bert)\n",
    "end_log_bert_train = time.time()\n",
    "\n",
    "time_log_bert_train = str(timedelta(seconds=(end_log_bert_train-start_log_bert_train)))\n",
    "\n",
    "print('Время обучения:', time_log_bert_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучается в течении 5 минут. Посмотрим на значение F1-меры на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера: 0.499 \n",
      "Время предсказания: 0:00:00.016925\n"
     ]
    }
   ],
   "source": [
    "f1_test_logistic_bert, time_log_bert_pred_test = pred_with_time(model_logistic_bert, features_test_bert, target_test_bert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке получили метрику F1 равной 0.499. Качество данной модели низкое. Возможно, это связано с недостаточным количеством информации и нужно увеличить размер исходной выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что сделали:**\n",
    "1. **Без использования модели BERT:**\n",
    "    1. Очистили комментарии от лишних символов и стоп-слов, привели к нижнему регистру и токенизировали.\n",
    "    2. Сравнили лемматизацию с учетом POS tag  и стемминг. Результат, полученный в процессе лемматизации, выглядит более подходящим для данной задачи, поэтому в проекте использовали лемматизацию токенов.\n",
    "    3. Разделили на три выборки: обучающую (60%), валидационную(20%) и тестовую (20%). \n",
    "    4. Перевели лемматизированные комментарии в векторы и рассчитали TF-IDF.\n",
    "    5. Построили 4 модели: LogisticRegressionCV, DecisionTreeClassifier, RandomForestClassifier и CatBoostClassifier. Проблему с дисбалансом классов решили их взвешиванием внутри моделей.\n",
    "    6. Проверили модели на адекватность, сравнив с моделью DummyClassifier.\n",
    "    \n",
    "    \n",
    "2. **С использованием BERT:**\n",
    "    1. Использовали модель DistilBERT, так как она быстрее и легче, чем BERt, при этом не уступает в результативности.\n",
    "    2. Токенизировали комментарии.\n",
    "    3. Модель DistilBERT принимает максимальное количество токенов в тексте по умолчанию равное 512, в связи с чем убрали аномальные длины, в качестве порогового значения взяли 75% квантиль.\n",
    "    4. Сформировали выборку из 20000 строк для последующего анализа, чтобы хватило оперативной памяти для получения результата.\n",
    "    5. Применили метод `padding`, создали маску и провели эмбединг.\n",
    "    6. Сформировали обучающую (80%) и тестовую(20%) выборки.\n",
    "    5. Обучили модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "1. **Без использования модели BERT:**\n",
    "\n",
    "    1. Необходимую метрику показала только модель LogisticRegression.\n",
    "\n",
    "    2. Результаты модели CatBoostClassifier близки к результатам модели LogisticRegression, но при этом CatBoostClassifier требует гораздо больше времени на обучение даже без подбора параметров.\n",
    "\n",
    "    3. Третий результат показала модель RandomForestClassifier, но у нее самое длительное время обучения и подбора гиперпараметров.\n",
    "\n",
    "    4. Последний результат показала модель DecisionTreeClassifier, время обучения на уровне модели CatBoostClassifier.\n",
    "    \n",
    "2. **С использованием BERT:**\n",
    "На тестовой выборке модель LogisticRegression получила метрику F1 равной 0.499. Качество данной модели низкое, относительно моделей без применения BERT. Возможно, это связано с недостаточным количеством информации и нужно увеличить размер исходной выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации:**\n",
    "Использовать для предсказаний модель LogisticRegression, она позволяет достигнуть требуемого качества и достаточно быстро обучается."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.796875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
